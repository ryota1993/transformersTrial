{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerForClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1WoiwcBS61-R4G5AXBpsgHQALyjDf2zlZ",
      "authorship_tag": "ABX9TyNQvO5I9zgEsdMixSDOd2w6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN8ZQ1-kQuqD",
        "colab_type": "text"
      },
      "source": [
        "**1. Environment Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnruiFv4QfZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow==2.0.0\n",
        "!pip install torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k99DlwvNQuU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JhYQjVT0u5Q",
        "colab_type": "text"
      },
      "source": [
        "**2. GPU Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dOXObnAo0WM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "7e708e58-e402-491e-c725-0c697f412030"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Feb 16 10:08:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    32W / 250W |   1661MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVs_C-gN1d9e",
        "colab_type": "text"
      },
      "source": [
        "**3. Input Data Requirement for BERT**<br>\n",
        "\n",
        "1.   Tokenize the sentences\n",
        "2.   Add \"CLS\" and \"SEP\" and \"PAD\" tokens to the sentences\n",
        "3.   Token_IDs → Turn tokens into IDs\n",
        "4.   Attention Masks → 0 for \"PAD\" token and 1 for all the other tokens\n",
        "5.   Segmentation_IDs → 0 for the first sentence and 1 for the second\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-RPPM-QQuZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "8e6c3b17-b71a-42e1-b749-685f185ebafe"
      },
      "source": [
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "sentence = 'I really enjoyed this movie a lot.'\n",
        "max_pad = 12\n",
        "\n",
        "################### 1. Token_IDs   #######################\n",
        "# Tokenize the sentence\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)\n",
        "\n",
        "# Add \"CLS\" and \"SEP\" tokens\n",
        "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "print(tokens)\n",
        "\n",
        "# Add \"PAD\" token\n",
        "padded_tokens = tokens + ['[PAD]' for _ in range(max_pad - len(tokens))]\n",
        "print(padded_tokens)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Turn tokens into IDs\n",
        "token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
        "print(\"1.Token_ids\")\n",
        "print(token_ids)\n",
        "print(\"\\n\")\n",
        "\n",
        "################### 2. Attention Mask   #######################\n",
        "# 0 for \"PAD\" token and 1 for all the other tokens\n",
        "attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
        "print(\"2.Attention masks(0 for 'PAD')\")\n",
        "print(attn_mask)\n",
        "print(\"\\n\")\n",
        "\n",
        "################### 3. Segmentation_IDs   #######################\n",
        "# Add 0 since we only have a single sequence as input\n",
        "# Usually, 0 for the first sentence and 1 for the second\n",
        "seg_ids = [0 for _ in range(len(padded_tokens))]\n",
        "print(\"3.Segmentation_ids(0 for the first sentence and 1 for the second)\")\n",
        "print(seg_ids)\n",
        "print(\"\\n\")"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.']\n",
            "['[CLS]', 'i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.', '[SEP]']\n",
            "['[CLS]', 'i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.', '[SEP]', '[PAD]', '[PAD]']\n",
            "\n",
            "\n",
            "1.Token_ids\n",
            "[101, 1045, 2428, 5632, 2023, 3185, 1037, 2843, 1012, 102, 0, 0]\n",
            "\n",
            "\n",
            "2.Attention masks(0 for 'PAD')\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "\n",
            "\n",
            "3.Segmentation_ids(0 for the first sentence and 1 for the second)\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhrN4A5s9B7u",
        "colab_type": "text"
      },
      "source": [
        "**4. Convert Input data into Torch Tensors and feed it to BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0JxRNTXYlA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To Torch tensors\n",
        "token_ids = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
        "attn_mask = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
        "seg_ids   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yv_BvsMYpWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "40c035a5-2c51-4740-956a-6bc6d473ebd7"
      },
      "source": [
        "#Feed them to bert\n",
        "hidden_reps, cls_head = bert_model(token_ids, attention_mask = attn_mask,\n",
        "                                   token_type_ids = seg_ids)\n",
        "\n",
        "print(hidden_reps.shape)\n",
        "print(cls_head.shape) # It is the size of \"CLS\""
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12, 768])\n",
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYLgUejRZiat",
        "colab_type": "text"
      },
      "source": [
        "**5. Use SST Dataset for Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNaY10GziwBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SSTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen):\n",
        "\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
        "\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'sentence']\n",
        "        label = self.df.loc[index, 'label']\n",
        "\n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
        "\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-WOgYp0jOTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "3d442898-a37f-46f3-9a14-d83ad21b6c2e"
      },
      "source": [
        "filePath = '/content/drive/My Drive/Transformers/data/SST-2/'\n",
        "\n",
        "#Creating instances of training and validation set\n",
        "train_set = SSTDataset(filename = filePath + \"train.tsv\",\n",
        "                       maxlen = 30)\n",
        "val_set = SSTDataset(filename = filePath + 'dev.tsv',\n",
        "                     maxlen = 30)\n",
        "\n",
        "#Creating intsances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 64, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = 64, num_workers = 5)\n",
        "\n",
        "print(train_set[0])\n",
        "print(\"\\n\")\n",
        "\n",
        "raw_data = pd.read_csv(filePath + \"train.tsv\", delimiter = '\\t')\n",
        "raw_data.head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([  101,  5342,  2047,  3595,  8496,  2013,  1996, 18643,  3197,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0]), 0)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates som...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>remains utterly satisfied to remain the same t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0       hide new secretions from the parental units       0\n",
              "1               contains no wit , only labored gags       0\n",
              "2  that loves its characters and communicates som...      1\n",
              "3  remains utterly satisfied to remain the same t...      0\n",
              "4  on the worst revenge-of-the-nerds clichés the ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEd0o2jzlT-7",
        "colab_type": "text"
      },
      "source": [
        "**6. Binary Classification Model for Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzIewzOGlNOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        #Instantiating BERT model object \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        #Freeze bert layers\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "        \n",
        "        #Classification layer\n",
        "        self.cls_layer = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs(B:Batch_size,T:Sequence length):\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Obtaining the representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86jmVL-XlNRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose \"True\" if you want to freeze the weights of parameters of bert layers\n",
        "net = SentimentClassifier(freeze_bert = True)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss() #computes the binary cross-entropy\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZrdSQf0o9t0",
        "colab_type": "text"
      },
      "source": [
        "**7. Start training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P43bOXyymvrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, criterion, opti, train_loader, val_loader, max_eps):\n",
        "\n",
        "    for ep in range(max_eps):\n",
        "        \n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            #Clear gradients\n",
        "            opti.zero_grad()  \n",
        "            #Converting these to cuda tensors\n",
        "            seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "\n",
        "            #Obtaining the logits from the model\n",
        "            logits = net(seq, attn_masks)\n",
        "\n",
        "            #Computing loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            #Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            #Optimization step\n",
        "            opti.step()\n",
        "\n",
        "            if (it + 1) % 500 == 0:\n",
        "                acc = get_accuracy_from_logits(logits, labels)\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMfeWClgyCFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lAoFiaXmvoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "36bf369b-7a78-48b3-ffdc-10ec34cd0996"
      },
      "source": [
        "#Enable GPU before training\n",
        "use_cuda = True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "\n",
        "# Train the model\n",
        "train(net, criterion, opti, train_loader, val_loader, max_eps=20)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 500 of epoch 1 complete. Loss : 0.6284043788909912 Accuracy : 0.703125\n",
            "Iteration 1000 of epoch 1 complete. Loss : 0.6111127138137817 Accuracy : 0.71875\n",
            "Iteration 500 of epoch 2 complete. Loss : 0.5759602785110474 Accuracy : 0.796875\n",
            "Iteration 1000 of epoch 2 complete. Loss : 0.5583184361457825 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 3 complete. Loss : 0.536167323589325 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 3 complete. Loss : 0.519092321395874 Accuracy : 0.8125\n",
            "Iteration 500 of epoch 4 complete. Loss : 0.505109965801239 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 4 complete. Loss : 0.48979440331459045 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 5 complete. Loss : 0.48039811849594116 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 5 complete. Loss : 0.46773675084114075 Accuracy : 0.78125\n",
            "Iteration 500 of epoch 6 complete. Loss : 0.46043115854263306 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 6 complete. Loss : 0.4509795606136322 Accuracy : 0.78125\n",
            "Iteration 500 of epoch 7 complete. Loss : 0.44407880306243896 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 7 complete. Loss : 0.43812376260757446 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 8 complete. Loss : 0.43051430583000183 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 8 complete. Loss : 0.42815667390823364 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 9 complete. Loss : 0.4191210865974426 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 9 complete. Loss : 0.4203431308269501 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 10 complete. Loss : 0.4094346761703491 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 10 complete. Loss : 0.4141472578048706 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 11 complete. Loss : 0.40110325813293457 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 11 complete. Loss : 0.40917715430259705 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 12 complete. Loss : 0.39385858178138733 Accuracy : 0.859375\n",
            "Iteration 1000 of epoch 12 complete. Loss : 0.40514448285102844 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 13 complete. Loss : 0.3874952793121338 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 13 complete. Loss : 0.4018355906009674 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 14 complete. Loss : 0.38185447454452515 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 14 complete. Loss : 0.3990909457206726 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 15 complete. Loss : 0.37681254744529724 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 15 complete. Loss : 0.39679011702537537 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 16 complete. Loss : 0.37227222323417664 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 16 complete. Loss : 0.39484164118766785 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 17 complete. Loss : 0.36815640330314636 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 17 complete. Loss : 0.3931751847267151 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 18 complete. Loss : 0.3644031584262848 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 18 complete. Loss : 0.3917361795902252 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 19 complete. Loss : 0.3609623610973358 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 19 complete. Loss : 0.39048197865486145 Accuracy : 0.796875\n",
            "Iteration 500 of epoch 20 complete. Loss : 0.3577931523323059 Accuracy : 0.875\n",
            "Iteration 1000 of epoch 20 complete. Loss : 0.38937899470329285 Accuracy : 0.796875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VupcfIy5T8OP",
        "colab_type": "text"
      },
      "source": [
        "**8. Save and re-load the model with Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JATeT-wa1Dxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the trained model\n",
        "PATH = '/content/drive/My Drive/Transformers/BertClassification.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImF_pzPoUFwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98625f2e-07c3-4676-b753-7f2b4700de7d"
      },
      "source": [
        "# Re-loading the saved model\n",
        "saved_net = SentimentClassifier(freeze_bert = True)\n",
        "saved_net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU4oZYB_VFsn",
        "colab_type": "text"
      },
      "source": [
        "**9. Let's do Sentiment Analysis!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrJE4cJxUFzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "e6e07c91-86e1-4d5d-9b06-f661ab3a5086"
      },
      "source": [
        "Max_len = 30\n",
        "\n",
        "sample_sentence = \"I was not sure if I would enjoy the movie but it turned out pretty good and fun.\"\n",
        "\n",
        "# Models can return full list of hidden-states & attentions weights at each layer\n",
        "model = bert_model.from_pretrained('bert-base-uncased',\n",
        "                                    output_hidden_states=True,\n",
        "                                    output_attentions=True)\n",
        "\n",
        "# Token_IDs into Torch tensors\n",
        "tokens = tokenizer.tokenize(sample_sentence)\n",
        "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "padded_tokens = tokens + ['[PAD]' for _ in range(Max_len - len(tokens))]\n",
        "token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
        "sample_input_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "\n",
        "# Attention Masks into Torch tensors\n",
        "attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
        "attn_masks = torch.tensor(attn_mask).unsqueeze(0)\n",
        "\n",
        "print(sample_input_ids)\n",
        "print(\"\\n\")\n",
        "print(attn_masks)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 101, 1045, 2001, 2025, 2469, 2065, 1045, 2052, 5959, 1996, 3185, 2021,\n",
            "         2009, 2357, 2041, 3492, 2204, 1998, 4569, 1012,  102,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0]])\n",
            "\n",
            "\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUG6kUe2UF3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "43ce80a5-4f11-4f9e-ba7e-5bc187692dc9"
      },
      "source": [
        "outputs = saved_net(sample_input_ids,attn_masks)\n",
        "probs = torch.sigmoid(outputs.unsqueeze(-1))\n",
        "print(probs)\n",
        "print(\"\\n\")\n",
        "\n",
        "if probs > 0.5:\n",
        "    print(\"Input sentence: \", sample_sentence)\n",
        "    print(\"Prediction: The sentence is positive\")\n",
        "else:\n",
        "    print(\"Input sentence: \", sample_sentence)\n",
        "    print(\"Prediction: The sentence is negative\")"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.5427]]], grad_fn=<SigmoidBackward>)\n",
            "\n",
            "\n",
            "Input sentence:  I was not sure if I would enjoy the movie but it turned out pretty good and fun.\n",
            "Prediction: The sentence is positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRTXH-6ujdR-",
        "colab_type": "text"
      },
      "source": [
        "**【Reference】**<br>\n",
        "・Medium Article:<br>\n",
        "https://medium.com/swlh/painless-fine-tuning-of-bert-in-pytorch-b91c14912caa<br>\n",
        "・Github Repo Referenced:<br>\n",
        "https://github.com/kabirahuja2431/FineTuneBERT<br>\n",
        "\n",
        "・Pytorch handling the model:<br>\n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "・GLUE Data preparation:<br>\n",
        "1. Run download_glue_data.py<br>\n",
        "https://github.com/nyu-mll/jiant/blob/master/scripts/download_glue_data.py<br>\n",
        "\n",
        "2. Run the code below:<br>python download_glue_data.py --data_dir \"Specify your directory here\" --tasks all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCZkVZ9jgoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}